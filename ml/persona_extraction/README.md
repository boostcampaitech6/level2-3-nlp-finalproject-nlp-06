# Chat Persona extraction Model for Korean

## Chat Persona extraction Modelì´ë€?

- ì‚¬ìš©ìì˜ ì¼ìƒ ì±„íŒ…ì—ì„œ ì‚¬ìš©ìì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ì¶”ì¶œí•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
- í•´ë‹¹ ëª¨ë¸ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ Ablation ì‹¤í—˜ë“¤ì€ ë‹¤ìŒ [ë¸”ë¡œê·¸](https://blog.naver.com/gypsi12/223396121146)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## How to Use
- ğŸ¤—[Huggingface Hub](https://huggingface.co/NLPBada/kobart-chat-persona-extraction-v2)ì— ì—…ë¡œë“œëœ ëª¨ë¸ì„ ê³§ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
```python
from transformers import AutoModel, AutoTokenizer

model = AutoModel.from_pretrained("NLPBada/kobart-chat-persona-extraction-v2")
tokenizer = AutoTokenizer.from_pretrained("NLPBada/kobart-chat-persona-extraction-v2")
```

## Finetuning

|                         | Hardware | Max len |   LR | Batch | Train Step |
| :---------------------- | -------: | ------: | ---: | ----: | ---------: |
| **Encoder** | Tesla V100 32G   |    500 | 1e-5 |    16 |         1M |
| **Decoder** | Tesla V100 32G   |    200 | 1e-5 |    16 |         1M |


## Evaluation Result

| ëª¨ë¸ | batch_size | epoch | ì–´íˆ¬ | Rouge-1-f1 | Rouge-2-f1 | Rouge-L-f1 | BLEU | ì „ì²´ ë°ì´í„°ì…‹ ê°œìˆ˜ | ë°ì´í„°ì…‹ |
| --- | --- | --- | ----- | --- | --- | --- | --- | --- | --- |
| KoBART | 16 | 4 | ì¡´ëŒ“ë§ | 0.5913 | 0.3789 | **0.5882** | 0.4493 | 41316 | [ë°ì´í„°ì…‹](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=71630)
| ET5 | 8 | 4 | ì¡´ëŒ“ë§ | 0.6127 | 0.3838 | **0.6086** | 0.4248 | 41316 | [ë°ì´í„°ì…‹](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=71630)
| KoBART | 16 | 8 | ë°˜ë§ | 0.5500 | 0.3306 | **0.5512** | 0.4373 | 10328 | [ë°ì´í„°ì…‹](https://huggingface.co/datasets/NLPBada/korean-persona-chat-dataset-v2)
| ET5 | 8 | 10 | ë°˜ë§ | 0.6068 | 0.3811 | **0.6026** | 0.4218 | 10328 | [ë°ì´í„°ì…‹](https://huggingface.co/datasets/NLPBada/korean-persona-chat-dataset-v2)

## ì¬í˜„ ë°©ë²•

### 1. requirements
cuda version : 11.2, linux-64 ì—ì„œ
```
# $ conda env create --name [ê°€ìƒí™˜ê²½ì´ë¦„] -f requirements.yaml
```

### 2. Config ì„¤ì •
- configsí´ë” ë‚´ì— config íŒŒì¼ì„ ìƒì„±
  ```
  {"model_name": "gogamza/kobart-base-v2", # ëª¨ë¸ ì´ë¦„
  "model_detail" : "kobart-baeline-rouge-bleu-by-val_bleu_avg", # ëª¨ë¸ ì„¸ë¶€ ì„¤ëª…
  "resume_path" : "./checkpoints/gogamza/kobart-base-v2kobart-baeline-rouge-bleu-by-val_bleu_avg.ckpt", # ë§Œì•½ í•™ìŠµì„ ì´ì–´ì„œ í•˜ê³  ì‹¶ì„ ê²½ìš° checkpoint íŒŒì¼ ê²½ë¡œ
  
  "metric": "val_rouge-l-f1", # í‰ê°€ì§€í‘œ
  "metric_mode": "max", # í‰ê°€ì§€í‘œ ê¸°ì¤€

  "wandb_entity" : "gypsi12", # wandb entityì´ë¦„
  "wandb_project" : "persona_extraction", # wandb í”„ë¡œì íŠ¸ ì´ë¦„
  "wandb_run_name" : "kobart-baeline-rouge-bleu-by-val_bleu_avg", # wandbìƒ ì‹¤í–‰ ì´ë¦„
  
  "batch_size": 16, # ë°°ì¹˜ í¬ê¸°
  "shuffle": true, # í•™ìŠµ ë°ì´í„° shuffle ì—¬ë¶€
  "learning_rate":1e-5, # learning rate
  "epoch": 10, # ìµœëŒ€ epoch
  
  "train_path":"./data/train/train.csv", # í•™ìŠµ ë°ì´í„° ê²½ë¡œ
  "dev_path":"./data/val/validation.csv", # ê²€ì¦ ë°ì´í„° ê²½ë¡œ
  "test_path":"./data/val/validation.csv", # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
  "predict_path":"./data/val/validation_csv"} # ì˜ˆì¸¡ ë°ì´í„° ê²½ë¡œ
  ```

### 3. í•™ìŠµ
```
python [ëª¨ë¸]_train.py --config "[ëª¨ë¸]/[ëª¨ë¸ config.json]"
```

### 4. í•™ìŠµ ê²°ê³¼
- í•™ìŠµ ê²°ê³¼ëŠ” ./best_model/ ê²½ë¡œì— .ptë¡œ ì €ì¥ë¨
- checkpointë“¤ì„ ./checkpoints/ ê²½ë¡œì— .ckptë¡œ ì €ì¥ë¨
