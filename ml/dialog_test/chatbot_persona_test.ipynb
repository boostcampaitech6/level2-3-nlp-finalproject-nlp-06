{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference\n",
    "\n",
    "langchain을 통한 inference\n",
    "\n",
    "https://python.langchain.com/docs/integrations/llms/llamacpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추출모델 변경 (kobart -> ET5)\n",
    "- 회고 프롬프트 변경\n",
    "- repetition 바꾸기\n",
    "- 유사도 기반 반환 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain - SOLAR, Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpu_layers = -1  # The number of layers to put on the GPU. The rest will be on the CPU. If you don't know how many layers there are, you can use -1 to move all to GPU.\n",
    "n_batch = 4096  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "\n",
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hwyew\\miniconda3\\envs\\true_friend\\lib\\site-packages\\langchain_core\\utils\\utils.py:159: UserWarning: WARNING! c is not default parameter.\n",
      "                c was transferred to model_kwargs.\n",
      "                Please confirm that c is what you intended.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 435 tensors from ../g_eval/solar/OPEN-SOLAR-KO-10_7B.Q5_K_S.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 48\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,46592]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,46592]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,46592]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   97 tensors\n",
      "llama_model_loader: - type q5_K:  337 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 700/46592 vs 695/46592 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 46592\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 48\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 34B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 10.85 B\n",
      "llm_load_print_meta: model size       = 6.97 GiB (5.52 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.17 MiB\n",
      "llm_load_tensors:        CPU buffer size =  7139.94 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    96.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   96.00 MiB, K (f16):   48.00 MiB, V (f16):   48.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    10.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    99.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.name': 'LLaMA v2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '48', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '16', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '2'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# Make sure the model path is correct for your system!\n",
    "solar = LlamaCpp(\n",
    "    model_path=\"../g_eval/solar/OPEN-SOLAR-KO-10_7B.Q5_K_S.gguf\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    callback_manager=callback_manager,\n",
    "    temperature=0.9,\n",
    "    top_p=0.95,\n",
    "    top_k=30,\n",
    "    max_tokens=256,\n",
    "    c=2048,\n",
    "    stop=[\"예원:\", \"지우:\", \"\\n\", \"ᄏ\"*6, \"ᄒ\"*6, \"ㅠ\"*6, \"ᄋ\"*6, \"ㅋ\"*6, \"ㅎ\"*6, \"ㅠ\"*6, \"ㅇ\"*6],\n",
    "    model_kwargs={\n",
    "        'min_p':0.7,\n",
    "        'repeatition_penalty': 1.9,\n",
    "        'no_repeat_ngram_size': 6,\n",
    "        'repeat_last_n' : 10,\n",
    "        'early_stopping': True\n",
    "    },\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페르소나 추출\n",
    "\n",
    "kobart -> et5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kobart model\n",
    "# from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "# extract_model = BartForConditionalGeneration.from_pretrained(\"NLPBada/kobart-chat-persona-extraction-v2\", cache_dir='./cache')\n",
    "# extract_tokenizer = AutoTokenizer.from_pretrained(\"NLPBada/kobart-chat-persona-extraction-v2\", cache_dir='./cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hwyew\\miniconda3\\envs\\true_friend\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "extract_tokenizer = AutoTokenizer.from_pretrained(\"NLPBada/et5-persona-extraction\", token ='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', cache_dir='./cache')\n",
    "extract_model = T5ForConditionalGeneration.from_pretrained(\"NLPBada/et5-persona-extraction\", token ='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', cache_dir='./cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페르소나 추출 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 채팅체의 문제인걸까?\n",
    "banmal_input = [\"초코 안바른건 다이제 아님\", \"원래는 초콜릿 사묵으려햇는데\", \"다이소에 가나초콜릿밖에 안남음;\", \"으;\", \"과자 개편식하는사람\", \n",
    "                \"꼬북칩 맛있남\", \"기억이 안나네\", \"ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\", \"츄러스 먹을까\", \"후..\", \"노노\", \"real 츄러스\", \"ㅇㅇ\", \n",
    "                \"놀랍게도\", \"공차는 없지만 츄러스는 파는 동네\", \"대충 이런거 팜\", \"근데 아이스크림이 더 짱맛이다\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[BOS] 초코 안바른건 다이제 아님 [SEP] 원래는 초콜릿 사묵으려햇는데 [SEP] 다이소에 가나초콜릿밖에 안남음; [SEP] 으; [SEP] 과자 개편식하는사람 [SEP] 꼬북칩 맛있남 [SEP] 기억이 안나네 [SEP] ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ [SEP] 츄러스 먹을까 [SEP] 후.. [SEP] 노노 [SEP] real 츄러스 [SEP] ㅇㅇ [SEP] 놀랍게도 [SEP] 공차는 없지만 츄러스는 파는 동네 [SEP] 대충 이런거 팜 [SEP] 근데 아이스크림이 더 짱맛이다 </s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banmal_input = '[BOS] ' + ' [SEP] '.join(banmal_input) + ' </s>'\n",
    "banmal_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[45102,  9186,  8830,  9251,  9189,  9432,  9191, 19542, 25789,  9189,\n",
       "          9186,  8199,  9188,  8830,  9186, 23274, 19518,  9201,  9241,  9790,\n",
       "          8415,  9187,     1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = extract_model.generate(extract_tokenizer(banmal_input, return_tensors='pt', padding='max_length', truncation=True, max_length=500)['input_ids'], max_length=200, num_beams=4, early_stopping=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나는 다이소에 가나 초콜릿이 있다,나는 츄러스를 안 먹는다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조금 더 정제된 형태..?\n",
    "new_input = [\"초코 안바른건 과자 아니야\", \"원래는 초콜릿 사먹으려고 했었는데\", \"다이소에 가나초콜릿밖에 안남아서 슬펐어\",\n",
    "                \"꼬북칩 맛있을까?\", \"기억이 안나네\",  \"츄러스 먹을까\", \"공차는 없지만 츄러스는 파는 동네야\", \"대충 이런거 팔고 있더라\", \"근데 아이스크림이 더 맛있다\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[BOS] 초코 안바른건 과자 아니야 [SEP] 원래는 초콜릿 사먹으려고 했었는데 [SEP] 다이소에 가나초콜릿밖에 안남아서 슬펐어 [SEP] 꼬북칩 맛있을까? [SEP] 기억이 안나네 [SEP] 츄러스 먹을까 [SEP] 공차는 없지만 츄러스는 파는 동네야 [SEP] 대충 이런거 팔고 있더라 [SEP] 근데 아이스크림이 더 맛있다 </s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = '[BOS] ' + ' [SEP] '.join(new_input) + ' </s>'\n",
    "new_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[45102,  9186,  8830, 25789,  9192,  9241,  9790,  8415,  9188,  8830,\n",
       "          9251,  9189,  9432,  9191, 19542, 25789, 10452,  9241,  9626,  8413,\n",
       "          9188,  8830,  9186, 23274, 19518,  9201,  9241,  9790,  8415,  9187,\n",
       "             1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = extract_model.generate(extract_tokenizer(new_input, return_tensors='pt', padding='max_length', truncation=True, max_length=500)['input_ids'], max_length=200, num_beams=4, early_stopping=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나는 초콜릿을 안 먹는다,나는 다이소에 가나 초콜릿밖에 안 남았다,나는 츄러스를 안 먹는다.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동어 반복 에러는 확실히 있는 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(x):\n",
    "    new_list = []\n",
    "    lst = x.split(',')\n",
    "    for i in lst:\n",
    "        i = i.replace('.', '')\n",
    "        if '다 나는' in i:\n",
    "            tmp = i.split('다 나는')\n",
    "            new_list.append(tmp[0] + '다')\n",
    "            new_list.append('나는' + tmp[1])\n",
    "        \n",
    "        else:\n",
    "            new_list.append(i.strip())\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나는 초콜릿을 안 먹는다', '나는 다이소에 가나 초콜릿밖에 안 남았다', '나는 츄러스를 안 먹는다']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessing(extract_tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - 지우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['new_input', 'prev_conversation', 'user_age', 'user_name', 'user_persona', 'user_sex'], template='지금부터 아래의 [챗봇 정보]를 가진 인물이 되어 대화를 수행한다.\\n[챗봇 정보]\\n- 이름: 지우\\n- 나이: 25세\\n- 직업: 대학생, 커뮤니케이션학과 전공\\n\\n[사용자 기본 정보]\\n- 이름: {user_name}\\n- 나이: {user_age}\\n- 성별: {user_sex}\\n\\n[대화 예시]\\n{user_name}: 넌 이름이 뭐야?\\n지우: 나는 지우야! 너는 {user_name}이지?\\n\\n\\n[현재 발화 관련 정보]\\n{user_persona}\\n\\n지금까지의 프롬프트를 읽고 [챗봇 정보]의 인물이 되어 대답하고, [사용자 정보]와 [현재 발화 관련 정보]에 기반하여 친절하고 예의있게 답변하라.\\n{prev_conversation}\\n{user_name}: {new_input}\\n지우: ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DEFAULT_TEMPLATE =  \"\"\"지금부터 아래의 [챗봇 정보]를 가진 인물이 되어 대화를 수행한다.\n",
    "[챗봇 정보]\n",
    "- 이름: 지우\n",
    "- 나이: 25세\n",
    "- 직업: 대학생, 커뮤니케이션학과 전공\n",
    "\n",
    "[사용자 기본 정보]\n",
    "- 이름: {user_name}\n",
    "- 나이: {user_age}\n",
    "- 성별: {user_sex}\n",
    "\n",
    "[대화 예시]\n",
    "{user_name}: 넌 이름이 뭐야?\n",
    "지우: 나는 지우야! 너는 {user_name}이지?\\n\n",
    "\n",
    "[현재 발화 관련 정보]\n",
    "{user_persona}\n",
    "\n",
    "지금까지의 프롬프트를 읽고 [챗봇 정보]의 인물이 되어 대답하고, [사용자 정보]와 [현재 발화 관련 정보]에 기반하여 친절하고 예의있게 답변하라.\n",
    "{prev_conversation}\n",
    "{user_name}: {new_input}\n",
    "지우: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(_DEFAULT_TEMPLATE)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.utils.math import cosine_similarity\n",
    "\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def make_embed(text: str) -> List[float]:\n",
    "    return embeddings.embed_query(text)\n",
    "\n",
    "def make_embeds(text: List[str]) -> List[List[float]]:\n",
    "    return embeddings.embed_documents(text)\n",
    "\n",
    "def get_cosine_similarity(user_input_embed: OpenAIEmbeddings, user_persona: dict, k: int, threshold: float):\n",
    "    top_k = {}\n",
    "    top_k_list = []\n",
    "    \n",
    "    top_k = dict(sorted(user_persona.items(), key=lambda x: cosine_similarity([user_input_embed], [x[1]])[0][0])[::-1])\n",
    "\n",
    "    for key, values in top_k.items():\n",
    "        if len(top_k_list) >= k:\n",
    "            break\n",
    "        \n",
    "        if cosine_similarity([user_input_embed], [values])[0][0] >= threshold:\n",
    "            print(key, cosine_similarity([user_input_embed], [values])[0][0])\n",
    "            top_k_list.append(key)\n",
    "    \n",
    "    return top_k_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cos_sim 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"친구가 없어 ㅠㅠ\"\n",
    "user_input_embed = make_embed(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_persona = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리에 하나씩 추가\n",
    "persona = [\"나는 친구가 없다\", \"나는 가지조림을 좋아한다\", \"나는 동물을 좋아한다\", \"어제 친구를 만났다\", \"친구와 마라샹궈를 먹었다\"]\n",
    "for user_persona_text in persona:\n",
    "    user_persona[user_persona_text] = make_embed(user_persona_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 친구가 없다 0.9335896420897338\n",
      "어제 친구를 만났다 0.8811745361116202\n",
      "친구와 마라샹궈를 먹었다 0.8601573289381883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['나는 친구가 없다', '어제 친구를 만났다', '친구와 마라샹궈를 먹었다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cosine_similarity(user_input_embed, user_persona, 5, 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대화 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_history = {'history' : [], 'jiwoo_history' : []}\n",
    "\n",
    "solar_chain = LLMChain(prompt=prompt, llm=solar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def make_conversation(user_name, user_age, user_sex):\n",
    "    print('## 챗봇 지우와의 대화를 시작합니다. 대화를 종료하고 싶다면 \"quit\"을 입력해주세요. ##')\n",
    "    new_input = ''\n",
    "    prev_conversation = []\n",
    "    user_persona = {}\n",
    "    \n",
    "    info = {\n",
    "        'user_name' : user_name,\n",
    "        'user_age' : user_age,\n",
    "        'user_sex' : user_sex,\n",
    "        'user_persona' : user_persona,\n",
    "        'prev_conversation' : prev_conversation,\n",
    "        'new_input' : new_input\n",
    "    }\n",
    "\n",
    "    print('## 초기 info : ', info)\n",
    "    cnt = 1\n",
    "\n",
    "    while True:\n",
    "        print(f'## {cnt} turn conversation ##')\n",
    "        print(f'## prev conversation : {prev_conversation}')\n",
    "        # 새로운 input 추가하기\n",
    "        new_input = input()\n",
    "        if new_input == 'quit':\n",
    "            print('## 대화 종료 ##')\n",
    "            break\n",
    "        dialog_history['history'].append(new_input)\n",
    "        print(f'## {user_name}: {new_input}')\n",
    "\n",
    "        info['new_input'] = new_input\n",
    "\n",
    "        # 누적 페르소나가 있을 경우\n",
    "        if len(user_persona.keys()) >= 3:\n",
    "            # 코사인 유사도에 따라서 top-3개의 user-person를 뽑아오자\n",
    "            # threshold 추가\n",
    "            top_k = get_cosine_similarity(make_embed(new_input), user_persona, 3, 0.8)\n",
    "            info['user_persona'] = top_k\n",
    "            print('## 정렬된 user persona top-3', info['user_persona'])\n",
    "\n",
    "        model_output = solar_chain.invoke(info)\n",
    "        print('## model output : ', model_output)\n",
    "\n",
    "        model_output = model_output[\"text\"]\n",
    "        print(type(model_output), model_output)\n",
    "        print(\"ᄏ\"*10 in model_output, \"ㅠ\"*10 in model_output, \"ᄒ\"*10 in model_output)\n",
    "        print()\n",
    "\n",
    "        if (\"ᄏ\"*10 in model_output) or (\"ㅠ\"*10 in model_output) or (\"ᄒ\"*10 in model_output):\n",
    "            print(\"## Same token detected ##\")\n",
    "            model_output = model_output[:10]\n",
    "\n",
    "        print(f'## 지우: {model_output}')\n",
    "        \n",
    "        dialog_history['jiwoo_history'].append(model_output)\n",
    "        prev_conversation.append({f'{user_name}: {new_input}\\n지우: {model_output}'})\n",
    "        \n",
    "        if len(dialog_history['history']) >= 7:\n",
    "            print('## 사용자의 대화가 7 turn 이상 쌓였기에 사용자 페르소나 분석을 시작합니다. ##')\n",
    "            model_input = '[BOS] ' + ' [SEP] '.join(dialog_history['history']) + ' </s>'\n",
    "            persona_output = extract_model.generate(extract_tokenizer(model_input, return_tensors='pt', padding='max_length', truncation=True, max_length=500)['input_ids'], max_length=200, num_beams=4, early_stopping=True)\n",
    "            \n",
    "            persona_output = extract_tokenizer.decode(persona_output[0], skip_special_tokens=True)\n",
    "            final_persona_output = postprocessing(persona_output)\n",
    "\n",
    "            print('## 유저 페르소나 : ', final_persona_output)\n",
    "\n",
    "            # 딕셔너리에 하나씩 추가\n",
    "            for user_persona_text in final_persona_output:\n",
    "                user_persona[user_persona_text] = make_embed(user_persona_text)\n",
    "\n",
    "            print('## 유저 페르소나 임베딩 : ', user_persona)\n",
    "        \n",
    "        # raw 대화 기록 5-turn 이상이 될 경우\n",
    "        if len(prev_conversation) > 5:\n",
    "            print('## 이전 대화 기록 삭제 ##')\n",
    "            prev_conversation = prev_conversation[1:]\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    with open(f\"./dialog_history/dialog_history_{datetime.today().strftime('%Y%m%d')}_{datetime.today().strftime('%H%M')}.txt\", \"w\") as f:\n",
    "        for i in range(len(dialog_history['history'])):\n",
    "            f.writelines(f'\\n{user_name}\\n' + dialog_history['history'][i] + '\\n')\n",
    "            f.writelines(f'\\n지우\\n' + dialog_history['jiwoo_history'][i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 챗봇 지우와의 대화를 시작합니다. 대화를 종료하고 싶다면 \"quit\"을 입력해주세요. ##\n",
      "## 초기 info :  {'user_name': '예원', 'user_age': '25', 'user_sex': '여자', 'user_persona': {}, 'prev_conversation': [], 'new_input': ''}\n",
      "## 1 turn conversation ##\n",
      "## prev conversation : []\n",
      "## 예원: 안녕함~\n",
      "ᄏᄏ 안녕하세요~ 안녕한가요?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18208.28 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    10 runs   (    0.44 ms per token,  2284.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18207.99 ms /   174 tokens (  104.64 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:        eval time =   15447.83 ms /     9 runs   ( 1716.43 ms per token,     0.58 tokens per second)\n",
      "llama_print_timings:       total time =   33857.16 ms /   183 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## model output :  {'user_name': '예원', 'user_age': '25', 'user_sex': '여자', 'user_persona': {}, 'prev_conversation': [], 'new_input': '안녕함~', 'text': 'ᄏᄏ 안녕하세요~ 안녕한가요?'}\n",
      "<class 'str'> ᄏᄏ 안녕하세요~ 안녕한가요?\n",
      "False False False\n",
      "\n",
      "## 지우: ᄏᄏ 안녕하세요~ 안녕한가요?\n",
      "## 2 turn conversation ##\n",
      "## prev conversation : [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}]\n",
      "## 예원: 너 지금 뭐해?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ᄒᄒ 나는 과제 중이었어 너는 뭐해?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18208.28 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /    12 runs   (    0.14 ms per token,  6908.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3288.14 ms /    37 tokens (   88.87 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2123.19 ms /    11 runs   (  193.02 ms per token,     5.18 tokens per second)\n",
      "llama_print_timings:       total time =    5456.18 ms /    48 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## model output :  {'user_name': '예원', 'user_age': '25', 'user_sex': '여자', 'user_persona': {}, 'prev_conversation': [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}], 'new_input': '너 지금 뭐해?', 'text': 'ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}\n",
      "<class 'str'> ᄒᄒ 나는 과제 중이었어 너는 뭐해?\n",
      "False False False\n",
      "\n",
      "## 지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?\n",
      "## 3 turn conversation ##\n",
      "## prev conversation : [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}]\n",
      "## 예원: 나는 버그를 고치고 있었어..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ᄏᄏ 그럼 그 버그는 어떻게 고쳐?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18208.28 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /    11 runs   (    0.14 ms per token,  7115.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3936.03 ms /    46 tokens (   85.57 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1896.95 ms /    10 runs   (  189.70 ms per token,     5.27 tokens per second)\n",
      "llama_print_timings:       total time =    5882.08 ms /    56 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## model output :  {'user_name': '예원', 'user_age': '25', 'user_sex': '여자', 'user_persona': {}, 'prev_conversation': [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}], 'new_input': '나는 버그를 고치고 있었어..', 'text': 'ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}\n",
      "<class 'str'> ᄏᄏ 그럼 그 버그는 어떻게 고쳐?\n",
      "False False False\n",
      "\n",
      "## 지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?\n",
      "## 4 turn conversation ##\n",
      "## prev conversation : [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}, {'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}]\n",
      "## 예원: 글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18208.28 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    19 runs   (    0.30 ms per token,  3339.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4965.90 ms /    58 tokens (   85.62 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:        eval time =    3525.28 ms /    18 runs   (  195.85 ms per token,     5.11 tokens per second)\n",
      "llama_print_timings:       total time =    8554.29 ms /    76 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## model output :  {'user_name': '예원', 'user_age': '25', 'user_sex': '여자', 'user_persona': {}, 'prev_conversation': [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}, {'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}], 'new_input': '글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?', 'text': 'ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?'}\n",
      "<class 'str'> ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?\n",
      "False False False\n",
      "\n",
      "## 지우: ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?\n",
      "## 5 turn conversation ##\n",
      "## prev conversation : [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}, {'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}, {'예원: 글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?\\n지우: ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?'}]\n",
      "## 예원: 다른 버그가 더 있으면 안되지 않을까..??\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18208.28 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /    20 runs   (    0.14 ms per token,  6922.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5575.16 ms /    67 tokens (   83.21 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:        eval time =    3672.06 ms /    19 runs   (  193.27 ms per token,     5.17 tokens per second)\n",
      "llama_print_timings:       total time =    9312.01 ms /    86 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## model output :  {'user_name': '예원', 'user_age': '25', 'user_sex': '여자', 'user_persona': {}, 'prev_conversation': [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}, {'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}, {'예원: 글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?\\n지우: ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?'}], 'new_input': '다른 버그가 더 있으면 안되지 않을까..??', 'text': 'ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!'}\n",
      "<class 'str'> ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!\n",
      "False False False\n",
      "\n",
      "## 지우: ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!\n",
      "## 6 turn conversation ##\n",
      "## prev conversation : [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}, {'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}, {'예원: 글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?\\n지우: ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?'}, {'예원: 다른 버그가 더 있으면 안되지 않을까..??\\n지우: ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!'}]\n",
      "## 예원: 너무해.. 가지마\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   18208.28 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     6 runs   (    0.14 ms per token,  7067.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4730.25 ms /    55 tokens (   86.00 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1000.10 ms /     5 runs   (  200.02 ms per token,     5.00 tokens per second)\n",
      "llama_print_timings:       total time =    5746.03 ms /    60 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## model output :  {'user_name': '예원', 'user_age': '25', 'user_sex': '여자', 'user_persona': {}, 'prev_conversation': [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}, {'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}, {'예원: 글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?\\n지우: ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?'}, {'예원: 다른 버그가 더 있으면 안되지 않을까..??\\n지우: ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!'}], 'new_input': '너무해.. 가지마', 'text': ''}\n",
      "<class 'str'> \n",
      "False False False\n",
      "\n",
      "## 지우: \n",
      "## 이전 대화 기록 삭제 ##\n",
      "## 7 turn conversation ##\n",
      "## prev conversation : [{'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}, {'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}, {'예원: 글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?\\n지우: ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?'}, {'예원: 다른 버그가 더 있으면 안되지 않을까..??\\n지우: ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!'}, {'예원: 너무해.. 가지마\\n지우: '}]\n",
      "## 예원: 가지 말라고!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ᄒᄒ안돼! 나 과제 마저 끝내야해! 다음에 보자!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18208.28 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    17 runs   (    0.14 ms per token,  6990.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2604.91 ms /    29 tokens (   89.82 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:        eval time =    3152.03 ms /    16 runs   (  197.00 ms per token,     5.08 tokens per second)\n",
      "llama_print_timings:       total time =    5814.29 ms /    45 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## model output :  {'user_name': '예원', 'user_age': '25', 'user_sex': '여자', 'user_persona': {}, 'prev_conversation': [{'예원: 안녕함~\\n지우: ᄏᄏ 안녕하세요~ 안녕한가요?'}, {'예원: 너 지금 뭐해?\\n지우: ᄒᄒ 나는 과제 중이었어 너는 뭐해?'}, {'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}, {'예원: 글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?\\n지우: ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?'}, {'예원: 다른 버그가 더 있으면 안되지 않을까..??\\n지우: ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!'}, {'예원: 너무해.. 가지마\\n지우: '}], 'new_input': '가지 말라고!!', 'text': 'ᄒᄒ안돼! 나 과제 마저 끝내야해! 다음에 보자!'}\n",
      "<class 'str'> ᄒᄒ안돼! 나 과제 마저 끝내야해! 다음에 보자!\n",
      "False False False\n",
      "\n",
      "## 지우: ᄒᄒ안돼! 나 과제 마저 끝내야해! 다음에 보자!\n",
      "## 사용자의 대화가 7 turn 이상 쌓였기에 사용자 페르소나 분석을 시작합니다. ##\n",
      "## 유저 페르소나 :  ['나는 버그를 고치고 있다']\n",
      "## 유저 페르소나 임베딩 :  {'나는 버그를 고치고 있다': [-0.015480743333762998, -0.006309295380939505, -0.0088310304682068, -0.013616708697893234, -0.010437273159228409, 0.019261693099966, -0.026612072517163212, -0.001272435151797532, -0.015150241174688843, 0.0022226301397042327, 0.007998163611729654, 0.0008064264346224313, -0.005833371396429525, -0.020451502362749036, -0.0049476245111501815, -0.01963185656121031, 0.0034008721435693414, 0.004623731948222686, -0.0007977507576033475, -0.019830157484125782, 0.009287124267292977, 0.005635070007852777, 0.013603488574277366, -0.014317374318211697, -0.0001799173724521538, -0.005000505005613655, 0.0009435850425140857, -0.025342942512684968, 0.00034888684458683154, 0.0004552673958410373, 0.0350332810159232, -0.005116180854421864, -0.018428826243488853, 0.005572274653508041, -0.001779756697064561, 0.004613816622680148, -4.694170157429017e-05, 0.0008824420289983547, -0.00463364680810395, 0.0025729629498634646, 0.007317328642496268, 0.004508056099414477, 0.008883910962670272, -0.011706403163706655, 0.00433619449240819, 0.03069708419520863, -0.01767528199135202, -0.004524581021103675, -0.0066100529603698695, 0.006140739037667824, -0.0074032589803381356, -0.006788524163522815, -0.032442140512503236, -0.030115400618755533, 0.006504291971442923, 0.004088317873102575, 0.011884875298182152, 0.006378700797092175, -0.012195547737493779, -0.028925591355972495, -0.0070132657993312985, 0.013762130057667785, -0.014264493823748225, -0.003909846204288354, -0.00020976589642381907, 0.022579939470936165, 0.018071883837182962, 0.007892402622802708, 0.006259720150210637, 0.00156988758390861, 0.021561992746481965, 0.030829285431367315, 0.0020408539056473206, -0.014568556666913193, 0.03294450334726112, -0.003529768115993419, -0.019830157484125782, 0.0023316961595351454, 0.0023911864829759145, -0.004636952071838555, 0.030644205563390262, 0.0031546476904697526, -0.011772503781785995, -0.002392839114843217, 0.02101996860955392, 0.021694193982640646, -0.002354831375862915, 0.02692935548394405, -0.005562359327965502, -0.03902575275998009, 0.005942437649091076, 0.02525040071605134, -0.009022721794975612, 0.024629055837428082, -0.005390498186620491, 0.006259720150210637, -0.023954830464341357, 0.034742436433729, -0.012155887366646174, -0.0034041771744733086, 0.004696442628109962, -0.019962358720284464, -0.02633445085255253, 0.0001599839266404748, -0.0393959162212244, 0.0010476933995737289, 0.02823814492794735, -0.004256874216374257, 0.006755473854483144, -0.0126119802344098, 0.008745100130364931, 0.02736561863194515, -0.011289969735468083, -0.039210832627957146, 0.008361716545504754, 0.0182437463755118, -0.004722882875341698, -0.028872710861509023, -0.03336754730296891, -0.007191737468145519, 0.01787358291426749, 0.00671581348363554, 0.009829148404221022, -0.0022127152798229696, -0.018428826243488853, -0.01036456294500241, -0.027920863823811613, -0.015269222287231658, 0.0044089051722954655, 0.007852742251955104, 0.05742813875623721, 0.012863162583111296, 0.023677208799730676, -0.011494882117175314, -0.0035000228378577153, -0.02671783350609016, 0.0020028459338363802, 0.010840486463851114, -0.020054900516918092, -0.022368419355727375, 0.007423089165761937, 0.03294450334726112, -0.02016066150584504, -0.03786238188178369, 0.023069084976045838, 0.00832205617465715, 0.03574716582853498, -0.00638200606082678, 0.02723341739578647, -0.012347578693414988, -0.014753637466212798, -0.0067686939780990125, 0.03167537148013778, -0.012043515850250019, -0.0062200597793630324, 0.0026456736297507397, -0.013160614898807056, 0.01335891675304508, -0.012274867547866436, -0.01275740159418435, -0.005820151272813657, 0.008963231704365481, 0.032627220380480285, -0.024206013744365405, 0.014171952958437147, 0.041854853625840585, -0.011475051466090238, -0.030009639629828586, -0.009743218066379155, 0.0014756943195608678, -0.012142667243030307, 0.033631949775286274, -0.0019978885038957487, 0.014290934070979961, -0.010100160472685046, 0.009187973805835241, 0.0034801928852645505, 0.017120036799485552, -0.011137938779546873, 0.0125392700201838, -0.04177553474679047, -0.011204039397626214, 0.016313610190240142, 0.010172871618233596, 0.012096396344713491, 0.01745053895855971, 0.035086161510386675, 0.01327298641520321, 0.011739453938407602, -0.004600596499064279, 0.014872618578755612, 0.014039751722278466, -0.008930180929664536, -0.0019103053013559408, -0.6248350583130676, -0.013986871227814992, -0.011137938779546873, 0.024047372260974986, 0.00011960064576624424, 0.018865091254135054, 0.008447647814669173, 0.000874179451738437, -0.02043828317045572, 0.012605370638263143, -0.007231397838993124, 0.007251228024416926, 0.018878310446428372, -0.0029381685155058673, 0.00817663574620515, -0.02320128434955942, 0.002063988889144452, -0.012519440300421274, -0.0012145972273934274, 6.233073353099318e-05, -0.02399449176651151, 0.002326738496763876, -0.01972439835784394, -0.001060087207255946, 0.013907551417442335, 0.0037611200464404745, 0.014727197218981062, -0.002242460325128035, -0.002832407526578922, 0.028185264433483875, -0.010338122697770673, 0.033473308291895855, 0.011065228565320873, 0.003923066327904222, 0.04418159165694318, 0.007390038856722267, -0.01684241513487487, 0.010357952417533199, 0.01788680210656081, 0.050870964893346984, -0.014198393205668883, -0.025197522084232968, 0.02868762913088687, 0.010708285227692432, 0.0034240073598971106, 0.00504016537646126, 0.00433619449240819, -0.015414642715683657, 0.009928298865678758, -0.004653476993527752, -0.023399587135119995, -0.010305071923069727, 0.008110535128125809, 0.02781510283488467, 0.00320918058396989, 0.012645031009110746, 0.01964507761614873, -0.02357144781080373, 0.007661051390847566, -0.01444957555437038, -0.014780077713444533, 0.007826302936045918, -0.021945375400019593, -0.005430158557468096, -0.030882165925830787, 0.0011774156879314575, -0.019750838605075673, -0.010543034148155356, -0.020226761192601826, -0.022725361762033266, -0.00653073221867466, -0.024761257073586767, -0.014436355430754512, 0.02789442357657988, 0.0035991737649767267, 0.02488023911745213, 0.03336754730296891, -0.018653569276281163, -0.02547514374884365, -0.001579802560205192, -0.02064980514830961, -0.02407381250820672, -0.017622401496888547, 0.00018074363017814553, 0.011990635355786546, 0.01372246968682018, -0.025726325166222593, -0.039078633254443565, -0.0027844846948867183, -0.0026374111689061413, 0.04238365857047531, 0.022064355581239856, 0.009954739112910496, -0.01181877468010281, 0.0030455819034694775, 0.019341013841661207, -0.004237044030950455, -0.0032108332158371925, 0.023558228618510414, 0.008844250591822667, -0.023359925832949838, -0.0038371355244010787, 0.02297654317941221, 0.0035826486104568915, 0.03085572567859905, 0.021654532680470493, -0.02509176109530602, -0.05208721626600686, 0.01364314894512497, -0.006249804824668098, 0.008791370097359195, -0.00780647228496084, -0.008183245342351809, -0.008044434510046468, 0.009439155223214186, -0.02897847185043597, -0.011871655174566283, -0.007819692408576709, 0.002135046937164425, -0.01640615012422867, 0.020345743236467193, -0.03151672999674736, 0.020927426812920293, -0.00627955033563444, 0.0030918521032943787, 0.0083947673202057, 0.01756952100242507, -0.014462795677986248, -0.010761165722155904, -0.011018957667004059, 0.0019830157484125783, -0.013378746472807606, -0.0010237318673123083, -0.014066191969510202, -0.0010476933995737289, -0.01787358291426749, 0.023439246574645047, -0.018124764331646434, 0.016287169943008408, 0.00211521698457126, -0.00646132680252199, 0.011336240633784897, -0.013259766291587344, 0.015784805245605417, -0.0012806977290574495, 0.002796052419465922, -0.02400771095880483, -0.019301354402136154, 0.014780077713444533, 0.01685563432716819, 0.019605416313978573, 0.010899977485783797, -0.018865091254135054, 0.004993894943805721, 0.015798026300543836, 0.013372136876660947, 0.020993528362322184, -0.015520403704610603, -0.022064355581239856, -0.004775762904143895, 0.012929263201190639, 0.005440073417349359, -0.0018541197759885009, -0.03989827905598229, 0.01943355563829484, -0.044974799073895275, -0.01803222439765791, 0.00838815679273649, -0.009690337571915682, -0.02905779259213118, 0.006755473854483144, -0.0012732614677311831, -0.01823052532057338, -0.008916960806048667, 0.021482672004786756, 0.005760661182203526, -0.014396695059906907, 0.0029315584536979333, -0.03196621606233198, -0.004141197901904772, 0.02452329671114624, 0.020173880698138354, -0.01705393525008366, 0.0009807665819760556, 0.029401513943498648, 0.01730511853010771, 0.01567904425667847, 0.02723341739578647, -0.005750745856660987, 0.009961349640379705, -0.0066232730839857375, 0.014965159444066688, -0.008778149973743326, 0.005945742447164405, -0.005033555314653325, -0.004838558724149907, -0.010159651494617727, 0.01854780828735422, 0.0023498737130916453, 0.03344686618201902, 0.017754600870402124, 0.027841543082116404, 0.011706403163706655, -0.03810034596951442, 0.01130318985908395, -0.030485564079999843, -0.020570484406614402, -0.012506220176805406, 0.008051044106193126, -0.006524122156866726, 0.006335735628171242, -0.011435391095242633, 0.0007002524623516384, -0.014502456048833852, 0.02209079582847159, 0.022870782190485266, -0.016657333404252718, 0.04359990994313519, -0.02640055053930932, 0.019605416313978573, -0.01756952100242507, -0.009564745931903658, 8.00436080660906e-05, -0.02605682732529675, 0.0013286205607496528, 0.02413991219496351, -0.011567592331401314, 0.04727509872041124, 0.014066191969510202, 0.0018871700850281714, -0.023518567316340257, -0.00824273543296194, -0.0019598805320848087, 0.028952031603204233, 0.01647225167363056, -0.010529814024539487, 0.01787358291426749, -0.01686885538210661, 0.019539316627221782, 0.012949092920953165, 0.011514711836937842, -0.003671884212033364, -0.00037140235306819226, 0.005892861952700932, 0.020239982247540245, 0.03989827905598229, 0.05695221430606595, 0.00011887767025600145, -0.021416570455384865, 0.02386229053035283, -0.032442140512503236, -0.017913242353792543, 0.008434427691053304, -0.008269175680193676, -0.01833628630950033, -0.025580904737770596, 0.015798026300543836, 0.017186136486242343, 0.04693137364375356, 0.025937847144076487, 0.01291604307757477, 0.011270140015705555, -0.010992517419772323, 0.01394721178828994, 0.01614174951455641, 0.009452375346830055, -0.0021383519680683916, -0.02736561863194515, -0.020319302989235455, -0.005198806394190402, -0.027841543082116404, -0.008718659883133195, 0.004501446037606543, -0.01690851482163166, 0.01590378728947078, -0.00697360589414497, 0.0038371355244010787, 4.61670885941516e-05, 0.010424053035612542, 0.014515676172449721, -0.01866678846857448, -0.006144043835741153, 0.02559412393006391, 0.02466871713959824, -0.0027382142622311796, -0.025409042199441758, -0.024919898556977182, 0.013603488574277366, -0.02494633880420892, 0.01290943348142811, -0.007039706046563035, 0.030485564079999843, -0.0008208859157234575, 0.006286160397442374, -0.01298214369565411, -0.022923662684948738, 0.02728629789024994, -0.0052417720287726115, 0.006586917511211462, 0.005995317677893273, -0.000888225833080297, 0.028396786411337766, -0.008414597039968226, -0.017318337722401024, 0.009445765750683396, 0.022289098614032166, -0.0074164791039540035, -0.014052971845894333, 0.0030406242406982083, -0.006887675090641826, -0.01648547086592388, 0.010186091741849465, -0.006514206831324187, -0.025369382759916702, -0.03738645743161243, 0.015070920432993634, -0.009201192998128558, -0.02560734498500233, 0.02209079582847159, 0.020121000203674883, -0.015930227536702517, 0.006434886555290253, -0.021628092433238755, -0.009822538808074365, 0.04293890189969667, -0.03225705691923598, 0.010899977485783797, 0.0021714022771080624, 0.01767528199135202, 0.004441955481335136, -0.024020932013743248, -0.04471039660157791, 0.003685104335649232, -0.032442140512503236, 0.011765894185639338, 0.00660013763482733, 0.009901858618447022, -0.006375395999018847, 0.0196979581106122, 0.008203075062114335, 0.017490200260729862, -0.01604920771792278, 0.015322102781695131, -0.015070920432993634, -0.0043229743687923225, 0.002354831375862915, 0.009749827662525813, 0.0045179709592957406, 0.028846270614277286, 0.022910443492655422, 0.008037823982577259, -0.010913196678077114, 0.03236281790816292, -0.02728629789024994, -0.02628157035808906, -0.014727197218981062, -0.019896259033527673, 0.005585494777123909, -0.007251228024416926, 0.06953775708721167, -0.02108606829631071, 0.021033187801847236, -0.015718705558848627, 0.01393399166467407, 0.03704273608024496, 0.010866926711082851, -0.007198347529953453, -0.0011988982723919244, 0.005397108248428426, -0.005364057939388755, -0.009683727044446472, 0.01634005043747188, -0.04558292289758011, -0.015137021051072976, 0.028317465669642557, -0.013239935640502265, -0.03574716582853498, -0.005370668001196689, 0.008302226454894623, -0.000544089984969833, -0.0003794583513446971, 0.009868808775068627, -0.024404314667280876, -0.018785770512439848, -7.813289071271336e-05, -0.036725453113464125, -0.004762543246189303, -0.011726233814791733, -0.007251228024416926, -0.005519394159044569, -0.01875933026520811, -0.0064381913533635825, -0.020094559956443145, -0.0016475556937365168, -0.011904705017944679, -0.01730511853010771, -0.018402385996257115, -0.014277713947364093, -0.008996281547743876, -0.003671884212033364, 0.02370364904696241, -0.01247977992957367, -0.0198433785390642, 0.010880146834698718, -0.013709249563204311, -0.0332882246986286, 0.01553362382822647, -0.0175166405079616, -0.010582694519002959, 0.018045443589951225, 0.0007485884520106674, -0.016459030618692142, -0.010622354889850564, 0.019962358720284464, 0.024192792689426982, 0.010053890505690782, 0.02720697714855473, -0.005089740607190128, -0.0024572871010552556, -0.012869773110580506, 0.0013831535706651092, 0.005859811643661262, 0.007555290401920619, 0.008123755251741678, 0.014436355430754512, 0.009472205997915132, -0.02581886696285622, -0.020610143846139455, -0.0041147576546730355, 0.011475051466090238, -0.00638200606082678, 0.02486701806251371, -0.004203993721910784, 0.013920771541058202, 0.02744493937364036, -0.019790498044600726, 0.014727197218981062, -0.011997245883255755, 0.024324993925585667, 0.003108377257814214, -0.020715904835066398, -0.01604920771792278, 0.0005887078439657287, 0.002098691830051425, -0.007713931419649762, -0.029877438393669905, 0.014515676172449721, 0.02546192269390523, -0.011389121128248369, -0.0031199449823934174, -0.025197522084232968, -0.020121000203674883, -0.005466513664581096, 0.0018970851777400726, -0.02685003474224884, 0.02495955985914734, -0.004418820497838005, -0.011977415232170678, -0.0037214596755928697, -0.03281230024845734, 0.003105072226910247, 0.014317374318211697, -0.017199357541180762, -0.04590020586436095, -0.028634748636423395, -0.0017053936181406213, -0.003932981187785485, -0.007859352779424313, -0.01714647704671729, -0.03122588913984336, -0.01561294456992168, 0.005611935024355646, -0.0038867109879605847, 0.03402855162111722, -0.005572274653508041, 0.00786596237557097, -0.004504750835679873, -0.007105806664642376, 0.01299536381926998, -0.02612292887469864, -0.016459030618692142, 0.008070874757278204, 0.03455735656575194, 0.01705393525008366, 0.004855083645839104, 0.002083819074568254, 0.01430415419459583, 0.00012228598337571747, 0.009511866368762736, 0.0021218270463791945, -0.028291025422410822, 0.0006808354348946617, -0.013087904684581056, 0.026083267572528483, 0.0007147119434526646, 0.016895295629338346, 0.02021354200030851, 0.0029266007909266637, -0.026374110292077584, 0.0183891668039638, 0.005968877430661537, 0.0010947900317476, -0.019512876379990045, -0.00246389716286319, -0.0023878814520719477, -0.021191829285237655, -0.006801744287138683, -0.011342850229931555, -0.0046766124426861596, 0.0019103053013559408, -0.01364314894512497, -0.00941271497598245, 0.02470837657912329, 0.01698783556332687, 0.016445811426398827, -0.029983199382596852, -0.007178517344529651, 0.02509176109530602, 0.012360798817030855, -0.023730089294194148, -0.01430415419459583, -0.01394721178828994, -0.0037148496137849357, 0.017252238035644237, 0.023518567316340257, 0.029375073696266914, -0.021813174163860912, 0.004389074986871663, -0.03667257261900066, 0.0327065429848206, 0.0012212072892013614, -0.04235721646059847, 0.02064980514830961, -0.01372246968682018, -0.014290934070979961, -0.008599678770590381, -0.014357034689059302, -0.022394859602959113, 0.004127977778288904, -0.0037049345210730346, -0.005165756085150732, 0.026387331347016003, 0.0198433785390642, -0.005053385500077128, -0.024999219298672392, 0.0452127594363358, 0.0038007804172880792, 0.0173712182168645, 0.03172825197460125, 0.05227229613398392, 9.698186962104945e-05, -0.038629147188858945, -0.004759237982454698, -0.004511360897487806, -0.02392839021710962, 0.004967454696573984, 0.02313518466280263, -0.014568556666913193, -0.02707477591239605, 0.019592197121685254, 0.0037115445828809685, 0.00393959124959342, -0.003966031496825157, 0.005324397568541151, 0.0058267613346215915, -0.0033083315110889015, -0.014238053576516488, -0.015097360680225371, -0.020054900516918092, 0.03426651198355774, -0.015850906795007308, 0.011078448688936742, -0.009710167291678208, -0.021945375400019593, 0.018865091254135054, 0.014700756971749324, -0.0077469817286894335, 0.03537700236729067, 0.008844250591822667, -0.005717695547621316, -0.0084674775344317, -0.019618637368916992, -0.006960385770529101, 0.009987789887611441, -0.013405186720039342, 0.030088960371523796, -0.01611530926732467, -0.011752674062023469, 0.019208812605502525, 0.004551021268335411, -0.014978379567682557, -0.0321248575457224, -0.019367454088892944, 0.03442515346694816, -0.018931190940891844, 0.009254073492592031, -0.016591231854850823, 0.007033095984755101, 0.03537700236729067, 0.017966122848256015, -0.0024011015756878157, -0.019764057797368992, 0.005552444468084239, -0.003658664321248134, -0.0053376176921570186, 0.025369382759916702, -0.012440119558726065, 0.015110580803841239, -0.03442515346694816, 0.0028291024956749546, -0.034504476071288474, -0.0035991737649767267, 0.01811154513935312, 0.03796814287071064, -0.005902777278243471, -0.032309937413699454, -0.022791461448790056, 0.01021914158522786, -0.001156759186574004, -0.030829285431367315, 0.01422483345290062, 0.021654532680470493, -0.03426651198355774, 0.0037049345210730346, -0.0023350011904391126, -0.01771494143087707, 0.007628001081807894, 0.00795189364473539, -0.009373054605134845, -0.016829194079936452, 0.03947523510027451, -0.022447740097422585, -0.011514711836937842, -0.019790498044600726, -0.021985034839544646, 0.007145467035489981, 0.019341013841661207, -0.02371687010190083, 0.010305071923069727, -0.0036884093665531994, 0.011871655174566283, -0.023650768552498938, -0.010695065104076563, 0.014938719196834952, -0.010794216496856851, 0.022408078795252428, 0.013312645854728265, -0.0125392700201838, -0.029639476168584276, -0.008196465465967676, 0.000778746829905537, -0.009789488033373418, -0.030512004327231577, -0.034054993730994056, 0.015374982344836053, 0.003979251620441025, -0.016815974887643137, -0.03529768348824056, 0.01817764482610991, -0.04188129573571742, -0.024258894238828876, 0.0055094788335020295, 0.014925499073219084, -0.0006391094488359074, -0.00882442087206014, 0.03574716582853498, -0.0002685333825975366, 0.01793968260102428, -0.009002892075213086, -0.002311865974111343, -0.020187101753076774, -0.03265366249035713, -0.015150241174688843, -0.01283672233587956, -0.040136239418422814, 0.03431939247802122, 0.0194071153910631, -0.013762130057667785, -0.010906587081930456, -0.00876492985012746, -0.014185173082053016, 0.004501446037606543, 0.000958457623374278, 0.010853706587466982, 0.017609180441950128, -0.0185345872324158, -0.0008403029431804342, 0.038523386199932, -0.004551021268335411, 0.019975579775222883, 0.004240348829023784, -0.008745100130364931, 0.013563828203429761, -0.009710167291678208, -0.0247876973208185, -0.017767821925340543, -0.008811200748444274, 0.006527426954940055, -0.003242230893009561, 0.009458985874299265, -0.010747945598540037, 0.01334569662942921, -0.0058994720145088666, 0.00441221043603007, 0.003174477875893555, -0.007905622746418576, -0.004342804554216125, -0.010179481214380256, 0.01801900334271949, -0.0008981409257921982, -0.012103006872182702, 0.026731052698383474, -0.0009171447952823493, -0.023677208799730676, -0.01269130097610501, 0.02281790169602179, -0.015295662534463393, 0.029903878640901643, -0.00904255244606069, -0.003956116636943893, -7.740991520247056e-05, -0.01833628630950033, 0.006107688728628153, -0.011838604399865338, -0.00933339423428724, -0.0035132429614735832, -0.009875419302537837, 0.01239384866040925, -0.00627955033563444, 0.02562056417729565, -0.0037445948919206393, 0.0201342212586133, 0.004167638149136508, -0.0001186711058245035, 0.006725728809178078, 0.008130364847888335, 0.01634005043747188, -0.022831122750960213, -0.011197429801479556, -0.0012840027599614165, -0.01596988697622757, -0.01614174951455641, 0.017979343903194438, 0.004577461515567148, -0.018798989704733163, -0.01386789104659473, -0.005420243231925557, -0.012440119558726065, 0.010034059854605704, -0.01640615012422867, 0.014991599691298426, -0.012532660424037143, 0.012248428231957252, 0.041008765714425015, 0.003143080198721187, -0.03149029161216072, 0.003430617421705045, 0.017622401496888547, 0.013325865978344132, 0.014502456048833852, 0.22294386663478513, -0.026612072517163212, -0.01566582506438515, 0.008817810344590931, 0.019010511682587054, 0.02386229053035283, 0.008593068243121171, -0.00397264155863309, -0.008150195498973414, 0.015216341792768186, 0.024933119611915605, -0.006183704206588757, -0.0013914161479250267, -2.8092724484943434e-05, -0.011792334432871074, -0.0004891439335028699, -0.022870782190485266, 0.008963231704365481, -0.030882165925830787, -0.00830883605104128, 0.021231488724762708, 0.0030554969961813787, -0.014013311475046728, -0.004501446037606543, 0.00831544657851049, -0.011389121128248369, -0.017463760013498128, 0.025951066336369802, 0.006091163806938955, 0.019671517863380464, -0.02649309233594295, -0.0016830847177465031, 0.013709249563204311, -0.013266375887734001, 0.0121757170864087, -0.005535919080733766, 0.027101216159627784, -0.004636952071838555, 0.04291246351511004, 0.021469450949848336, 0.020253201439833564, 0.014238053576516488, 0.020266422494771983, 0.004475005790374807, -0.029163553581058124, 0.03828542583749147, -0.007046316108370969, -0.00634895575178711, -0.023214505404497838, 0.03926371312242062, -0.024457195161744348, -0.0255148031883687, -0.0009452375579660692, 0.036725453113464125, 0.009511866368762736, -0.010318292046685596, -0.001958228133048144, -0.0048154232749915, -0.019777276989662307, 0.028581868141959923, -0.0008502180358923354, 0.02663851276439495, -0.013246546167971475, 0.019341013841661207, -0.036566811630073706, -0.01298214369565411, -0.032785861863870704, 0.04722221822594777, 0.014542116419681457, -0.030300482349377687, -0.009763047786141682, -0.0016268991923790632, 0.01730511853010771, 0.014872618578755612, -0.042013495109231004, -0.02744493937364036, 0.013550608079813892, 0.004610511824606818, 0.032019096556795454, 0.014581776790529062, -0.010377783068618278, -0.0021879274316278976, 0.024549735095732873, -0.01604920771792278, -0.009452375346830055, -0.02254028003141111, 0.022262658366800428, 0.004157723289255245, -0.028291025422410822, -0.020980307307383764, 0.010503373777307751, -0.018732890017976372, -0.005317787506733216, -0.015441082962915393, 0.01422483345290062, 0.006887675090641826, -0.010357952417533199, 0.013524167832582156, 0.0031695202131222853, 0.0033050264801849348, -0.014436355430754512, 0.014290934070979961, 0.014489235925217985, 0.0003588019372987327, 0.002554785396306965, 0.01566582506438515, -0.003671884212033364, -0.01000101001122731, 0.001012990575082075, -0.043520587338794874, -0.01756952100242507, -0.011878264770712943, 0.010556254271771223, 0.01852136804012248, -0.011759283658170128, 0.0026456736297507397, 0.028291025422410822, -0.0214430107026166, 0.021138948790774183, -0.0014335552337429473, 0.03709561657470844, -0.0009196235684603245, 0.0038173055718079144, 0.020980307307383764, 0.009650677201068077, 0.00042924030657612647, -0.02654597283040642, 0.015480743333762998, -0.003268671140241297, -0.06091824766553621, 0.016511911113155617, -0.027035116472870997, 0.01641937117916709, -0.02633445085255253, -0.014251273700132357, 0.002386229053035283, 0.0037049345210730346, 0.0014657792268489666, -0.011574202858870524, 0.01386789104659473, 0.01823052532057338, 0.0018491622296325503, 0.010060500101837441, -0.010708285227692432, -0.02354500756357199, -0.035271241378363724, 0.021376911015859812, 0.007753591790497367, 0.00021255450897308384, 0.013339086101960001, -0.021165389038005918, -0.003850355648016947, -0.00882442087206014, 0.021469450949848336, 0.035271241378363724, 0.0012055083341998584, -0.03384347175314016, -0.044208033766820025, 0.008553407872273567, 0.006223364577436362, -0.037915262376247164, 0.006454716740714055, 0.06023080123751107, -0.020266422494771983, -0.024615836645134767, -0.02531650226545323, -0.16794822689857747, 0.01816442563381659, 0.024483635408976086, -0.008579848119505304, 0.002936515883638565, 0.023082304168339157, 0.021813174163860912, -0.009168143154750164, 0.0019185677622005394, 0.02108606829631071, -0.0043229743687923225, -0.01292265360504398, -0.03344686618201902, 0.009306953987055505, 0.005076520483574259, -0.002898508144658263, -0.023029423673875685, -0.009967959236526363, 0.02620224961639385, -0.006110993992362757, 0.0335790692808228, -0.015242782039999922, 0.006494376645900385, -0.0006432407374658662, 0.013398577123892684, 0.021905714097849437, 0.0022160200778962988, 0.012493000053189538, 0.005443378681083964, -0.0196979581106122, -0.0252239604688196, -0.009326784638140581, 0.03696341347590465, 0.002050768765528584, 0.019314573594429472, 0.008136975375357545, -0.019314573594429472, 0.015216341792768186, -0.008355106949358095, 0.005324397568541151, 0.005958962570780274, 0.03085572567859905, 0.011402341251864238, 0.02072912589000482, -0.02731273813748168, 0.007528850154688883, 0.0250785400403676, -0.008183245342351809, 0.01138251060077916, 0.006738948932793947, 0.007244617962608993, -0.0316224909856743, 0.005582189513389305, 0.010582694519002959, 0.004686527302567423, 0.012526049896567934, 0.009240853368976162, 0.01167335332032826, -0.005145925899726929, -0.010635575013466432, -0.014806517960676271, -0.007462749536609542, 0.01990947822582099, 0.014859398455139743, -0.009518475964909396, -0.003349644280973171, -0.026215468808687168, 0.021813174163860912, -0.02072912589000482, 0.01466109660090172, 0.009809318684458496, 0.0029332108527345977, 0.012949092920953165, -0.012658251132726615, -0.007092586541026508, -0.000584989655094936, -0.027127656406859522, 0.006044893374283417, 0.007515630031073015, -0.003784255262768244, 0.014039751722278466, 0.007760201852305301, -0.017979343903194438, 0.013590268450661497, -0.00404865750225497, 0.010847096991320323, 0.03638173176209666, -0.01138251060077916, 0.0032984164183770003, -0.0062431947628601644, 0.03461023706021542, -0.035218360883900256, 4.867167686909606e-05, -0.01948643613275831, 0.0088310304682068, 0.015018039938530162, -0.002206105218015035, 0.004246958890831718, 0.001801239397940347, 0.0004982327102811198, 0.003546293270513254, 0.004663392319070291, -0.038919991771053146, 0.038338306331954945, 0.014238053576516488, -0.00313977516781722, 0.016088869020092936, 0.01919559341320921, 0.03725425805809886, 0.0008593068708782447, -0.019222033660440944, 0.0098489790553061, 0.020570484406614402, 0.020200320945370092, 0.013484507461734551, 0.01854780828735422, -0.00904916204220735, 0.013775350181283652, 0.006358870611668373, 0.0037445948919206393, 0.0506594429154931, -0.026678172203920002, -0.011574202858870524, 0.01189809542179802, -0.007138856973682046, -0.027021895417932575, -0.052430937617374336, -0.02488023911745213, 0.018375947611670482, 0.018508146985184062, 0.0013410144848471888, 0.021918935152787856, 0.001595501515206695, 0.022751802009265003, -0.026532751775468003, 0.0013401881689135374, -0.02488023911745213, -0.031410969007820415, -0.01677631358547298, 0.012572320794884748, -0.0054731237263890295, 0.009954739112910496, -0.02685003474224884, 0.009954739112910496, -0.003840440555305046, 0.014568556666913193, -0.021918935152787856, 0.004987284881997786, 0.006282855133707769, -0.02232875805355722, -0.024536515903439558, 0.001678953370908885, -0.021720634229872384, 0.020266422494771983, 0.013973651104199123, 0.005172366146958666, -0.016432590371460408, -0.0020061509647403475, -0.0043097542451764545, -0.020319302989235455, -0.023954830464341357, -0.015414642715683657, -0.018706449770744638, -0.008123755251741678, 0.015163461298304712, -0.028740509625350342, 0.024615836645134767, 0.003290153724701764, 0.018693228715806216, -0.006586917511211462, -0.01614174951455641, -0.009240853368976162, 0.01992269928075941, 0.032574339886016816, -0.0053376176921570186, -0.0018095019752002645, -0.0183891668039638, -0.014859398455139743, -0.042753822031719624, -0.02474803788129345, 0.036275970773169706, -0.005714390749547987, -0.0001039017635243156, 0.016604452909789246, -0.021694193982640646, -0.0023085609432073762, -0.014793297837060402, -0.0034735828234566165, -0.014965159444066688, 0.006653018129290803, -0.0009444113002400774, 0.02029286274200372, -0.01503126006214603, -0.018931190940891844, 0.03646105064114676, -0.02481413756805024, 0.026003946830833274, 0.01715969623901061, -0.006702593360019671, 0.041907734120304053, -0.038787788672249364, -0.0005924259746288619, 0.004950929309223511, -0.036566811630073706, -0.0006990131048664805, -0.01657801266255751, -0.023756529541425885, -0.002292035788687541, -0.013841450799362994, -0.009815928280605155, 0.011501491713321974, 0.01861390797411101, -0.020451502362749036, -0.003946201311401354, -0.011104888936168478, -0.009835758931690232, 0.00686123484341009, -0.01883865100690332, 0.02101996860955392, -0.002049116366491919, -0.005605324962547712, 0.014938719196834952, -0.005165756085150732, 0.006729033607251408, 0.0040552675640629044, 0.020451502362749036, -0.015560064075458208, -0.03225705691923598, -0.058908788875924246, 0.01816442563381659, -0.007859352779424313, -0.020530823104444245, -0.002729951801386581, 0.00433619449240819, 0.019261693099966, -0.028925591355972495, -0.01291604307757477, 0.004028827316831168, 0.023743310349132567, -0.005407023108309689, 0.01341840684365521, -0.019499655325051626, -0.012149276839176965, -0.021548771691543546, 0.030591325068926787, 0.004587376841109687, 0.007998163611729654, 0.008480697658047568, -0.0019185677622005394, 0.0018128070061042315, 0.006117604054170692, 0.02421923293665872, -0.0318340129635282, 0.014568556666913193, -0.008797980624828405, 0.012949092920953165, -0.014039751722278466, -0.024972779051440658, -0.02195859459231291, -0.03283874235833418, 0.005483038586270294, -0.009505255841293527, -0.00419738366010285, -0.01189148489432881, -0.007350378485874662, 0.021429791510323284, 0.0252239604688196, 0.03114656839814815, -0.0016748221404865855, -0.01407941209312607, 0.01875933026520811, -0.0016128528692448626, -0.015018039938530162, -0.020900986565688555, -0.013385357000276816, -0.0003697498376162087, 0.0021433096308396613, 0.012506220176805406, 0.02390194996987788, 0.027392058879176884, -0.005882947092819669, -0.01730511853010771, 0.0022655955414558043, -0.05949047431502245, 0.022738580954326584, 0.013306036258581606, 0.0018194170679121657, -0.01181877468010281, 0.029533715179657333, -0.00897645182798135, -0.010205921461611991, -0.01692173587657008, 0.01538820246845192, -0.015004819814914293, 0.012083176221097624, -0.00809070447704073, 0.016459030618692142, -0.01756952100242507, -0.02016066150584504, -0.0016872159481688025, 0.009710167291678208, 0.0027200367086746796, -0.0038767958952486835, 0.03252145939155334, -0.020557263351675983, -0.009670506920830603, -0.006914115337873563, 0.026228689863625587, -0.011825384276249469, -0.0033050264801849348, -0.00949203571767766, -0.0166441123493143, -0.0038701858334407495, 0.011871655174566283, -0.009868808775068627, -0.004385770188798334, 0.022077576636178275, 0.015427862839299524, -0.07339802945775499, -0.0021003442290880897, 0.020530823104444245, 0.017252238035644237, 0.009287124267292977, 0.027762222340421194, 0.02789442357657988, 0.02472159763406171, -0.002110259321799991, -0.013114344931812794, -0.012440119558726065, -0.0007973375996365219, 0.020583703598907717, -0.022910443492655422, 0.004732797735222961, 0.002802662481273856, 0.008930180929664536, -0.006527426954940055, 0.0014616478800113485, 0.04103520782430185, -0.0008956621526142229, 2.166341564951682e-05, -0.020041679461979673, 0.025052099793135867, -0.015850906795007308, -0.009505255841293527, -0.00390323614248042, -0.005549139204349634, -0.020689464587834664, 0.013001973415416637, 0.03207197705125893, 0.012155887366646174, 0.02918999382828986, -0.030829285431367315, 0.026902915236712312, 0.021416570455384865, 0.019010511682587054, -0.0011501491247660697, -0.006395226184442649, 0.02715409665409126, -0.009749827662525813, -0.008811200748444274, -0.015930227536702517, -0.020570484406614402, -0.004488225913990675, 0.019737617550137254, -0.01788680210656081, -0.00021172825124709206, -0.010767776249625115, 0.07678237365283684, 0.011375901004632502, 6.248565321663792e-05, -0.01743731976626639, -0.00656708732578766, -0.01459499691414493, 0.015956667783934255, 0.010377783068618278, -0.004835253460415302, 0.006695983298211737, 0.030591325068926787, -0.012420288907640988, 0.005397108248428426, -0.05811558518426236, -0.0252239604688196, 0.0009609363965522533, -0.01772816062317039, 0.007363598609490531, -0.01943355563829484, 0.023320266393424785, 0.03831186422207811, -0.001898737693192056, -0.014687536848133457, 0.008196465465967676, 0.0055226989571178975, -0.005843286721972064, 0.001250952450921746, 0.004061877625870839, 0.002568005519922833, -0.022659260212631375, -0.009478815594061791, -0.01321349539327053, -0.028925591355972495, -0.004828643398607368, -0.013239935640502265, -0.009247463896445372, -0.03159605260108767, -0.01357704832704563, 0.02429855367835393, 0.030591325068926787, -0.009617626426367131, 0.02723341739578647, -0.007125636850066178, 0.01990947822582099, 0.036434612256560125, -0.019512876379990045, -0.004071792485752102, 0.005026945252845391, 0.0043097542451764545]}\n",
      "## 이전 대화 기록 삭제 ##\n",
      "## 8 turn conversation ##\n",
      "## prev conversation : [{'예원: 나는 버그를 고치고 있었어..\\n지우: ᄏᄏ 그럼 그 버그는 어떻게 고쳐?'}, {'예원: 글쎄.. 나도 잘 모르겠어. 쉽게 고칠 수 있을 줄 알았는데 왜일까?\\n지우: ᄏᄏᄏ그러게.. 그럼 그냥 다른 버그나 찾아보는게 어때?'}, {'예원: 다른 버그가 더 있으면 안되지 않을까..??\\n지우: ᄏᄏᄏ그건 그렇겠지? 그럼 나는 과제나 끝내야겠어. 다음에 봐!'}, {'예원: 너무해.. 가지마\\n지우: '}, {'예원: 가지 말라고!!\\n지우: ᄒᄒ안돼! 나 과제 마저 끝내야해! 다음에 보자!'}]\n",
      "## 대화 종료 ##\n"
     ]
    }
   ],
   "source": [
    "make_conversation(\"예원\", \"25\", \"여자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stopword issue 해결\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ㅋㅋㅋㅋㅋㅋ\" in \"ᄏ\"*256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ㅋㅋㅋㅋㅋㅋ\" in \"ㅋ\"*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ㅎㅎㅎㅎㅎㅎ\" in \"ᄒ\"*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ㅎㅎㅎㅎㅎㅎ\" in \"ㅎ\"*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"beomi/OPEN-SOLAR-KO-10.7B\", cache_dir='./cache'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"ᄒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"ㅎ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "true_friend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
